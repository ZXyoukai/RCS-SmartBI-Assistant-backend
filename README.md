# ML Pipeline API - Machine Learning com FastAPI

Esta Ã© uma API REST completa para upload e anÃ¡lise de dados usando Machine Learning. O sistema processa arquivos CSV ou SQL e retorna anÃ¡lises completas com insights automÃ¡ticos.

## ğŸš€ Funcionalidades

- **Upload de Arquivos**: CSV ou SQL dumps via API REST
- **Pipeline ML Completo**: PrÃ©-processamento, treinamento e avaliaÃ§Ã£o
- **MÃºltiplos Modelos**: RandomForest, SVM e Logistic Regression
- **AnÃ¡lise AutomÃ¡tica**: Insights em linguagem natural
- **VisualizaÃ§Ãµes**: Matriz de confusÃ£o e grÃ¡ficos de mÃ©tricas
- **Suporte SQL**: Processamento de dumps SQLite

## ğŸ“ Estrutura do Projeto

```
BI.AI/
â”œâ”€â”€ main.py                    # API FastAPI
â”œâ”€â”€ ml_pipeline.py             # Pipeline ML Universal
â”œâ”€â”€ analysis.py                # Gerador de insights automÃ¡ticos
â”œâ”€â”€ requirements.txt           # DependÃªncias (inclui drivers SQL)
â”œâ”€â”€ outputs/                   # GrÃ¡ficos e visualizaÃ§Ãµes gerados
â”œâ”€â”€ temp/                      # Arquivos temporÃ¡rios
â”œâ”€â”€ dados.csv                  # Dataset de exemplo (Iris)
â”œâ”€â”€ exemplo_simples.sql        # SQL bÃ¡sico SQLite
â”œâ”€â”€ exemplo_mysql.sql          # SQL MySQL/MariaDB
â”œâ”€â”€ exemplo_postgresql.sql     # SQL PostgreSQL
â”œâ”€â”€ exemplo_misto.sql          # SQL misto (vÃ¡rios dialetos)
â””â”€â”€ README.md                  # Este arquivo
```

## ğŸ› ï¸ Como Usar

### 1. InstalaÃ§Ã£o
```bash
py -m pip install -r requirements.txt
```

### 2. Iniciar a API
```bash
python main.py
```

A API estarÃ¡ disponÃ­vel em: http://localhost:8000

### 3. DocumentaÃ§Ã£o Interativa
Acesse: http://localhost:8000/docs

### 4. Endpoints Principais

#### POST /upload
Upload de arquivo CSV ou SQL para anÃ¡lise ML
- **Content-Type**: multipart/form-data
- **ParÃ¢metro**: file (arquivo CSV ou SQL)
- **Retorno**: JSON com mÃ©tricas, insights e caminhos dos grÃ¡ficos

#### GET /outputs/{filename}
Acesso aos grÃ¡ficos gerados (matriz de confusÃ£o, mÃ©tricas)

#### GET /health
Status da API e verificaÃ§Ã£o de saÃºde

## ğŸ“Š Exemplo de Uso

### Upload via cURL:
```bash
curl -X POST "http://localhost:8000/upload" \
     -H "accept: application/json" \
     -H "Content-Type: multipart/form-data" \
     -F "file=@dados.csv"
```

### Resposta da API:
```json
{
  "file_info": {
    "filename": "dados.csv",
    "file_type": "csv",
    "size_bytes": 2928
  },
  "pipeline_results": {
    "success": true,
    "data_info": {
      "rows": 150,
      "columns": 5,
      "features": 4,
      "target_classes": 3
    },
    "results": {
      "RandomForest": {
        "accuracy": 0.9333,
        "precision": 0.9333,
        "recall": 0.9333,
        "f1": 0.9333,
        "roc_auc": 0.9867
      }
    },
    "plots": [
      "outputs/confusion_matrix_RandomForest_20250929_205230.png",
      "outputs/metrics_RandomForest_20250929_205230.png"
    ]
  },
  "analysis": {
    "executive_summary": [
      "ğŸ“‹ 3/3 modelos treinados com sucesso",
      "ğŸ“Š Dataset: 150 linhas, 4 features",
      "ğŸ¯ 3 classes para prediÃ§Ã£o"
    ],
    "model_insights": {
      "RandomForest": "âœ… Excelente acurÃ¡cia (93.3%) | âœ… Excelente precisÃ£o | âœ… Excelente recall"
    },
    "recommendations": [
      "âœ… Modelos com boa performance - considere deploy em produÃ§Ã£o"
    ]
  }
}
```

## ğŸ“ Formatos Suportados

### CSV
- Ãšltima coluna deve ser o target/classe
- Colunas numÃ©ricas sÃ£o automaticamente detectadas
- Valores nulos sÃ£o tratados automaticamente

### SQL Universal ğŸ†•
- **MySQL/MariaDB**: AUTO_INCREMENT, ENGINE, CHARSET, tipos especÃ­ficos
- **PostgreSQL**: SERIAL, BOOLEAN, ARRAY, tipos especÃ­ficos  
- **SQLite**: Sintaxe nativa
- **SQL Server**: Tipos bÃ¡sicos (IDENTITY, NVARCHAR)
- **SQL Misto**: Combina sintaxes de diferentes SGBDs

#### Recursos SQL AvanÃ§ados:
- âœ… **DetecÃ§Ã£o automÃ¡tica** do dialeto SQL
- âœ… **ConversÃ£o universal** para SQLite
- âœ… **Limpeza de comentÃ¡rios** (-- # /* */)
- âœ… **NormalizaÃ§Ã£o de tipos** de dados
- âœ… **Processamento robusto** de statements
- âœ… **SeleÃ§Ã£o inteligente** da melhor tabela

## ğŸ”§ Arquivos de Exemplo

### Dados CSV
- **dados.csv**: Dataset Iris (classificaÃ§Ã£o multiclasse)

### Dumps SQL Universais ğŸ†•
- **exemplo_simples.sql**: SQLite bÃ¡sico (dataset Iris)
- **exemplo_mysql.sql**: MySQL/MariaDB com AUTO_INCREMENT, ENGINE, CHARSET
- **exemplo_postgresql.sql**: PostgreSQL com SERIAL, BOOLEAN, ARRAY
- **exemplo_misto.sql**: SQL complexo misturando sintaxes (anÃ¡lise de vendas)

### Teste Todos os Formatos:
```bash
# CSV tradicional
curl -F "file=@dados.csv" http://localhost:8000/upload

# SQLite simples  
curl -F "file=@exemplo_simples.sql" http://localhost:8000/upload

# MySQL/MariaDB
curl -F "file=@exemplo_mysql.sql" http://localhost:8000/upload

# PostgreSQL
curl -F "file=@exemplo_postgresql.sql" http://localhost:8000/upload

# SQL Misto (complexo)
curl -F "file=@exemplo_misto.sql" http://localhost:8000/upload
```

## ğŸš€ Melhorias Futuras

- Suporte a outros formatos (Excel, JSON)
- ParÃ¢metros customizÃ¡veis para modelos
- Dashboard web para visualizaÃ§Ã£o
- Armazenamento de histÃ³rico de anÃ¡lises
- Deploy em contÃªineres Docker

---

> ğŸ¤– **API pronta para produÃ§Ã£o!** Upload seus dados e obtenha insights instantÃ¢neos.
